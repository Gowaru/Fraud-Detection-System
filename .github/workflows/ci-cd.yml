name: MLOps - Fraud Detection CI/CD Pipeline

on:
  push:
    branches: [ main, develop ]
  pull_request:
    branches: [ main ]
  schedule:
    # RÃ©entraÃ®nement automatique chaque semaine
    - cron: '0 0 * * 0'
  workflow_dispatch:

env:
  PYTHON_VERSION: '3.10'
  MODEL_REGISTRY: 'models/'

jobs:
  # Job 1: Tests de qualitÃ© du code
  code-quality:
    runs-on: ubuntu-latest
    steps:
      - name: ğŸ“¥ Checkout code
        uses: actions/checkout@v3
      
      - name: ğŸ Setup Python
        uses: actions/setup-python@v4
        with:
          python-version: ${{ env.PYTHON_VERSION }}
          cache: 'pip'
      
      - name: ğŸ“¦ Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install flake8 black pylint
          pip install -r requirements.txt
      
      - name: ğŸ” Lint with flake8
        run: |
          flake8 . --count --select=E9,F63,F7,F82 --show-source --statistics
          flake8 . --count --exit-zero --max-complexity=10 --max-line-length=127 --statistics
      
      - name: ğŸ¨ Check code formatting
        run: black --check .
      
      - name: ğŸ“Š Pylint score
        run: pylint src/ --exit-zero

  # Job 2: Tests unitaires et d'intÃ©gration
  tests:
    runs-on: ubuntu-latest
    needs: code-quality
    steps:
      - name: ğŸ“¥ Checkout code
        uses: actions/checkout@v3
      
      - name: ğŸ Setup Python
        uses: actions/setup-python@v4
        with:
          python-version: ${{ env.PYTHON_VERSION }}
          cache: 'pip'
      
      - name: ğŸ“¦ Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt
          pip install pytest pytest-cov
      
      - name: ğŸ§ª Run unit tests
        run: |
          pytest tests/ -v --cov=src --cov-report=xml --cov-report=html
      
      - name: ğŸ“Š Upload coverage reports
        uses: codecov/codecov-action@v3
        with:
          files: ./coverage.xml
          flags: unittests
          name: codecov-umbrella

  # Job 3: Validation des donnÃ©es
  data-validation:
    runs-on: ubuntu-latest
    needs: tests
    steps:
      - name: ğŸ“¥ Checkout code
        uses: actions/checkout@v3
      
      - name: ğŸ Setup Python
        uses: actions/setup-python@v4
        with:
          python-version: ${{ env.PYTHON_VERSION }}
          cache: 'pip'
      
      - name: ğŸ“¦ Install dependencies
        run: |
          pip install -r requirements.txt
          pip install great-expectations ydata-profiling
      
      - name: âœ… Validate data schema
        run: python scripts/validate_data.py
      
      - name: ğŸ“ˆ Generate data profiling report
        run: python scripts/profile_data.py

  # Job 4: EntraÃ®nement du modÃ¨le
  train-model:
    runs-on: ubuntu-latest
    needs: [tests, data-validation]
    steps:
      - name: ğŸ“¥ Checkout code
        uses: actions/checkout@v3
      
      - name: ğŸ Setup Python
        uses: actions/setup-python@v4
        with:
          python-version: ${{ env.PYTHON_VERSION }}
      
      - name: ğŸ“¦ Install dependencies
        run: |
          pip install -r requirements.txt
      
      - name: ğŸš€ Train model
        run: python src/train.py
        env:
          MLFLOW_TRACKING_URI: ${{ secrets.MLFLOW_TRACKING_URI }}
          MLFLOW_EXPERIMENT_NAME: fraud-detection
      
      - name: ğŸ“Š Log metrics
        run: |
          echo "Model trained successfully"
          cat metrics/metrics.json
      
      - name: ğŸ’¾ Upload model artifacts
        uses: actions/upload-artifact@v3
        with:
          name: model-artifacts
          path: |
            models/
            metrics/
          retention-days: 30

  # Job 5: Ã‰valuation et validation du modÃ¨le
  evaluate-model:
    runs-on: ubuntu-latest
    needs: train-model
    outputs:
      deployment_ready: ${{ steps.check_metrics.outputs.deployment_ready }}
    steps:
      - name: ğŸ“¥ Checkout code
        uses: actions/checkout@v3
      
      - name: ğŸ Setup Python
        uses: actions/setup-python@v4
        with:
          python-version: ${{ env.PYTHON_VERSION }}
          cache: 'pip'
      
      - name: ğŸ“¦ Install dependencies
        run: pip install -r requirements.txt
      
      - name: ğŸ“¥ Download model artifacts
        uses: actions/download-artifact@v3
        with:
          name: model-artifacts
      
      - name: ğŸ“Š Evaluate model performance
        id: evaluate
        run: python scripts/evaluate_model.py
      
      - name: âœ… Check deployment criteria
        id: check_metrics
        run: |
          PRECISION=$(python -c "import json; print(json.load(open('metrics/metrics.json'))['precision'])")
          RECALL=$(python -c "import json; print(json.load(open('metrics/metrics.json'))['recall'])")
          DEPLOYMENT_READY=$(python -c "import json; print(json.load(open('metrics/metrics.json'))['deployment_ready'])")
          
          echo "Precision: $PRECISION"
          echo "Recall: $RECALL"
          echo "deployment_ready=$DEPLOYMENT_READY" >> $GITHUB_OUTPUT
          
          if [ "$DEPLOYMENT_READY" = "True" ]; then
            echo "âœ… Model meets deployment criteria"
          else
            echo "âš ï¸ Model does not meet deployment criteria"
            exit 1
          fi
      
      - name: ğŸ“ˆ Generate evaluation report
        run: python scripts/generate_report.py
      
      - name: ğŸ“¤ Upload evaluation report
        uses: actions/upload-artifact@v3
        with:
          name: evaluation-report
          path: reports/

  # Job 6: Tests de drift des donnÃ©es
  data-drift-detection:
    runs-on: ubuntu-latest
    needs: evaluate-model
    steps:
      - name: ğŸ“¥ Checkout code
        uses: actions/checkout@v3
      
      - name: ğŸ Setup Python
        uses: actions/setup-python@v4
        with:
          python-version: ${{ env.PYTHON_VERSION }}
          cache: 'pip'
      
      - name: ğŸ“¦ Install dependencies
        run: |
          pip install -r requirements.txt
          pip install evidently
      
      - name: ğŸ” Detect data drift
        run: python scripts/detect_drift.py
      
      - name: âš ï¸ Alert on drift
        if: failure()
        run: echo "Data drift detected! Model retraining recommended."

  # Job 7: Build Docker image
  build-docker:
    runs-on: ubuntu-latest
    needs: evaluate-model
    if: needs.evaluate-model.outputs.deployment_ready == 'True'
    steps:
      - name: ğŸ“¥ Checkout code
        uses: actions/checkout@v3
      
      - name: ğŸ“¥ Download model artifacts
        uses: actions/download-artifact@v3
        with:
          name: model-artifacts
      
      - name: ğŸ³ Set up Docker Buildx
        uses: docker/setup-buildx-action@v2
      
      - name: ğŸ” Login to Docker Hub
        uses: docker/login-action@v2
        with:
          username: ${{ secrets.DOCKER_USERNAME }}
          password: ${{ secrets.DOCKER_PASSWORD }}
      
      - name: ğŸ—ï¸ Build and push Docker image
        uses: docker/build-push-action@v4
        with:
          context: .
          push: true
          tags: |
            ${{ secrets.DOCKER_USERNAME }}/fraud-detection:latest
            ${{ secrets.DOCKER_USERNAME }}/fraud-detection:${{ github.sha }}
          cache-from: type=registry,ref=${{ secrets.DOCKER_USERNAME }}/fraud-detection:buildcache
          cache-to: type=registry,ref=${{ secrets.DOCKER_USERNAME }}/fraud-detection:buildcache,mode=max

  # Job 8: DÃ©ploiement staging
  deploy-staging:
    runs-on: ubuntu-latest
    needs: [evaluate-model, build-docker]
    if: needs.evaluate-model.outputs.deployment_ready == 'True' && github.ref == 'refs/heads/develop'
    environment:
      name: staging
      url: https://staging-fraud-detection.example.com
    steps:
      - name: ğŸ“¥ Checkout code
        uses: actions/checkout@v3
      
      - name: ğŸš€ Deploy to staging
        run: |
          echo "Deploying to staging environment..."
          # Ajoutez ici vos commandes de dÃ©ploiement (kubectl, helm, etc.)
      
      - name: ğŸ§ª Run smoke tests
        run: python scripts/smoke_tests.py --env staging
      
      - name: âœ… Staging deployment successful
        run: echo "Model deployed to staging"

  # Job 9: DÃ©ploiement production
  deploy-production:
    runs-on: ubuntu-latest
    needs: [evaluate-model, build-docker]
    if: needs.evaluate-model.outputs.deployment_ready == 'True' && github.ref == 'refs/heads/main'
    environment:
      name: production
      url: https://fraud-detection.example.com
    steps:
      - name: ğŸ“¥ Checkout code
        uses: actions/checkout@v3
      
      - name: ğŸš€ Deploy to production
        run: |
          echo "Deploying to production environment..."
          # DÃ©ploiement avec canary ou blue-green strategy
      
      - name: ğŸ§ª Run production smoke tests
        run: python scripts/smoke_tests.py --env production
      
      - name: ğŸ“Š Enable monitoring
        run: |
          echo "Enabling production monitoring..."
          # Configuration des alertes et monitoring
      
      - name: âœ… Production deployment successful
        run: echo "Model deployed to production"
      
      - name: ğŸ“¢ Send notification
        uses: 8398a7/action-slack@v3
        with:
          status: ${{ job.status }}
          text: 'Fraud Detection Model deployed to production!'
          webhook_url: ${{ secrets.SLACK_WEBHOOK }}
        if: always()

  # Job 10: Monitoring post-dÃ©ploiement
  post-deployment-monitoring:
    runs-on: ubuntu-latest
    needs: deploy-production
    if: success()
    steps:
      - name: ğŸ“¥ Checkout code
        uses: actions/checkout@v3
      
      - name: ğŸ“Š Setup monitoring dashboards
        run: |
          echo "Setting up monitoring dashboards..."
          python scripts/setup_monitoring.py
      
      - name: ğŸ”” Configure alerts
        run: |
          echo "Configuring performance alerts..."
          python scripts/configure_alerts.py